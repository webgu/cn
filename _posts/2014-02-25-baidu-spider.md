---
layout: post
title: 解读搜索引擎蜘蛛的更新策略
category: 杂记
---



百度搜索是怎么更新我们网站的？并赋予关键词排名，必须要了解百度蜘蛛baiduspider抓取过程中，针对不同情况采取对应更新策略，才能更充分的提升网站的收录量，让更多的页面参与排名?

为什么要研究搜索引擎蜘蛛？不知道它更新策略，就会导致排名周期很长。搜索引擎蜘蛛，也是一只蜘蛛，需要养，给它东西吃，养的又肥又大，把它卖了。当然是开个玩笑。

![illustration](/assets/img/posts/18.jpg "361格")


它是个程序，是抓取数据的，搜索引擎抓取的数据，通过各种各样的方法，进行挑选，它的功能在于能抓取数据。

蜘蛛其实是个形象的说法，谷歌叫为机器人。中国引申为蜘蛛。跟收录、 快照 有关系排名也有关系。蜘蛛更新策略跟很多因素都有关系。有些行业有些特殊性，商城京东 当当 门户有些是没法通用的。

搜索引擎对所有行业策略是不同的。不同行业用户需求不同，用千篇一律的方式做优化，是不行的，只能具体问题具体分析更新影响收录 快照排名 。首先要了解，为什么要更新为什么要爬取数据？爬取是蜘蛛的工作。搜索引擎前期数据来源是很少的。来自新浪、腾讯 网易等大网站。对内容没要求，随着网站发展，350万的网站，以每天以亿来计算更新的页面。前期抓取不会挑三拣四，随着后期的数量的增加，只能抓取有价值的东西。

百度搜索世界杯，需要提供最新的内容，就会进行更新。是不是所有蜘蛛知道的链接都会进行抓取吗？

蜘蛛不知道这个链接对应的内容的好坏，面对一个新的链接，正常情况下都会进行抓取。非正常是什么情况？非正常情况下，为什么网站不被抓取？网站为什么没收录？搜索引擎去了并不代表抓取。搜索引擎抓取网站有4个步骤：

    一 抓取

    二 筛选

    三 建立索引 

    四 输出结果

去了并不一定代表收录。去 ——过滤页面——建立索引正常情况下，发现的新连接都会去抓。什么情况下不去抓。

4个非常重要的情况：

nofollow屏蔽的会抓吗？搜索引擎是会去爬取页面，但是是不会建立快照，不建立索引，不会收录。但是有一种情况下是会收录的。

robots有个特例，就是这个网站是用robots进行屏蔽的，但是在外部存在链接，也会建立收录。不是说你屏蔽了，就不收录。什么情况下，蜘蛛不去，或者隔很久才去：

<br />
#####1 域名历史
<br />

![illustration](/assets/img/posts/19.jpg "361格")

很多人喜欢买老域名做网站 .老域名如果以前是做和你的网站是同行业的，就会留下很多外链，自然就会助推你的站。如果没有做站，这个域名是没有什么价值的。

老域名pr比较高的话，从百度讲，pr没有作用。但是对谷歌说，是有用的。pr可以劫持和作假。一个域名从来没有用过，301到一个pr高的网站，这个新域名在谷歌更新的时候，也有pr。www.tengsj.com pr3 www.tengsj.net 。把.net301到.com的站，下一次谷歌pr更新时，.net也变成pr4 再把301撤掉 变成.com .net都是pr4 这时候用.net做新站换友链就非常容易。但是在百度是没什么价值的。

pr值高，但是百度没排名，一点用都没有。当一个域名长期没有人使用，在半年之前做过网站，pr4 半年后，网站关掉了，域名放在那里。这时候搜索引擎会去很多次。访问不了，还去爬，会重复的去几次。一个网站关闭有可能是服务器不稳定，故障，如果尝试很多次，都不能访问，才会暂停访问。数据在数据库里有，但不去访问。做新站，这样的情况下，提交网址，也不会短期去访问。这就是域名历史。

新注册的域名，当然也会有不去访问的情况。这就会是乌龙事件。新注册的域名，之前被人用过，做网站后，站群 淘宝 灰色站等 这些域名被k后不续费，被回收。2个月后，就会被重新拿来卖。拉入黑名单的域名，重新卖，被你买到了，搜索引擎前期也不会访问。搜索引擎在单位时间内，对一个网站搜索的总次数，就可以了解到蜘蛛去的情况。很多网站上线后验证百度站长平台，发外链，提交网站，访问频率一直是0，那就是域名历史问题。

新站上线一周内，抓取有个周期，有个url索引数据库，存放了很多路径，以一个域名为单位存储，一般情况下上线2周还没抓取，2-3周一直是0 ，域名有问题，这就是被拉黑，或者有问题。会导致不去抓取。上线提交网址，不会马上抓取，过一段时间就会收录。拉黑了的域名，投诉百度，是没有作用的。打电话处理不过来，www.baidu.com 现在换成baidu.com 或者直接换新的域名。

<br />
#####2 目录前科
<br />

做着后发现某个目录下就不进行抓取了。某个目录不抓。目录前科问题。大量的网站对比，目录下面的内容质量过低，又大量更新，导致这个目录不抓取。出现在b2b平台。

<br />
#####3 链接等级
<br />

新发现的链接，都会抓取。现在很多新站，只抓首页，不抓内页。这就是链接等级。搜索引擎给一个网站读取数据或者提交后，这些链接是有等级的。每个链接都会有个针对性的等级。首页等级最高，一个新站的内页等级很低，因此，刚开始就不去抓。即使发现了也不去抓。这牵涉到结构问题，页面等级和结构是息息相关的。

首页 栏目页 内容页，三层结构 首页 频道页 栏目页 内容页 这是四层结构。

a 这就是页面等级，因此不会去抓取内页。网站结构一定要3层，不过于深。

b 很多以目录形式存在，例如汽车之家，每款汽车都是以目录页形式存在。

链接等级如果过于细分，也会导致搜索引擎不抓取。

<br />
#####4 信用等级
<br />

就是404 当一个链接第一次打不开，下次还会去访问。当一个链接多次打不开，就不会去访问了。当一个网站有规律的更新，搜索引擎会去，当更新一个月后，不再更新了，搜索引擎也会去。一般是2-3周以上。如果不是高质量内容，这种情况下不会去。这在博客非常多见。博客 淘宝客，博客上面是淘宝的链接，下面的内容，前期如果有规律，并且更新高质量内容一个月，后期拿些伪原创是可以的，前期是要有固定性的规律。信用等级是衡量网站好坏的，会根据规律去抓取，给网站给予排名。一个星期中停了一天没影响。正常情况下蜘蛛知道的链接，都是会去抓取的。但是上述的4个情况不会去抓。新站上线了2-3周还没去抓，域名前科，最好是直接换域名。

![illustration](/assets/img/posts/13.jpg "361格")

发外链，引蜘蛛，也是解决搜索引擎尽快抓取的好办法。

提交有2个办法 ：

    1 url提交

    2 百度站长反馈中心

各个搜索引擎提交方法是不一样的。

